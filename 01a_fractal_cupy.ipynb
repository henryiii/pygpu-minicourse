{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 2_000\n",
    "width = 3_000\n",
    "maxiterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import numba\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by checking to see which GPU we have, using a shell command (sadly CuPy does not seem to be able to query names; it is currently limited to numerical attributes):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a V100, the examples should run roughly 5x faster than on the K40's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandelbrot Fractal\n",
    "\n",
    "From the CPU course, we had the Mandelbrot fractal, which we will be covering today as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate a Mandelbrot fractal by applying the transform:\n",
    "\n",
    "$$\n",
    "z_{n+1}=z_{n}^{2}+c\n",
    "$$\n",
    "\n",
    "repeatedly to a regular matrix of complex numbers $c$, and recording the iteration number where the value $|z|$ surpassed some bound $N$, usually $N=2$. You start at $z_0 = c$.\n",
    "\n",
    "\n",
    "\n",
    "Let's set up some initial parameters and a helper matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(height, width, xp=np):\n",
    "    x,y = xp.ogrid[-1.5j:1.5j:height*1j, -2:2:width*1j]\n",
    "    c = x + y\n",
    "    fractal = xp.zeros(c.shape, dtype=xp.int32)\n",
    "    return c, fractal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "Let's try a Numpy run (we will use `%%time` instead of `%%timeit`, since this takes several seconds to run so we don't need a precision measurement and don't want to waste time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractal_x(c, f, maxiterations):\n",
    "    xp = cp.get_array_module(c)\n",
    "    f *= 0 # set to 0\n",
    "    z = c.copy()\n",
    "\n",
    "    for i in range(1, maxiterations+1):\n",
    "        z = z**2 + c                    # Compute z\n",
    "        diverge = xp.abs(z**2)  > 2**2  # Divergence criteria\n",
    "\n",
    "        z[diverge] = 2               # Keep number size small\n",
    "        f[~diverge] = i              # Fill in non-diverged iteration number\n",
    "        \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, fractal = prepare(height, width, np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = fractal_x(c, fractal, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba\n",
    "\n",
    "Let's do a quick check with Numba from the CPU course, just to see how fast we can get on single CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.vectorize([numba.int32(numba.complex128, numba.int32)])\n",
    "def on_each_numba(cxy, maxiterations):\n",
    "    z = cxy\n",
    "    for i in range(maxiterations):\n",
    "        z = z**2 + cxy\n",
    "        if abs(z) > 2:\n",
    "            return i\n",
    "    return maxiterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, fractal = prepare(height, width, np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = on_each_numba(c, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy: Numpy interface\n",
    "\n",
    "Now, let's try a CuPy run (We will run a synchronize call just for good measure, since we are not using the output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, fractal = prepare(height, width, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fractal_x(c, fractal, 20)\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy: Fuse interface\n",
    "\n",
    "This is a \"Numba vectorize\"-like interface for making elementwise interfaces and simple reductions. It's quite limited, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cp.fuse()\n",
    "def cupy_fuse_combine(z, c):\n",
    "    x = z**2 + c\n",
    "    return x, cp.abs(x**2)\n",
    "\n",
    "def fractal_fuse(c, f, maxiterations):\n",
    "    xp = cp.get_array_module(c)\n",
    "    f *= 0 # set to 0\n",
    "    z = c.copy()\n",
    "\n",
    "    for i in range(1, maxiterations+1):\n",
    "        z, az2 = cupy_fuse_combine(z, c)     # Compute z\n",
    "        diverge = az2  > 2**2  # Divergence criteria\n",
    "\n",
    "        z[diverge] = 2               # Keep number size small\n",
    "        f[~diverge] = i              # Fill in non-diverged iteration number\n",
    "        \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, fractal = prepare(height, width, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fractal_fuse(c, fractal, 20)\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy: Elementwise Kernel\n",
    "\n",
    "Now, let's try a custom elementwise kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_single = cp.ElementwiseKernel(\n",
    "    \"complex128 c, int32 maxiterations\",\n",
    "    \"int32 res\",\n",
    "    \"\"\"\n",
    "    res = 0;\n",
    "    complex<double> z = c;\n",
    "\n",
    "    for (int i=0; i<maxiterations; i++) {\n",
    "        z = z*z + c;\n",
    "\n",
    "        if(z.real()*z.real() + z.imag()*z.imag() > 4)\n",
    "            break;\n",
    "\n",
    "        res = i;\n",
    "    }\n",
    "    \n",
    "    \"\"\",                                \n",
    "    \"fract_el\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "cupy_single(c, 20)\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also try writing everything ourselves with a pure, raw CUDA kernel:\n",
    "\n",
    "> Note: width/height are confusing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupy_kernel = cp.RawKernel(\"\"\"\n",
    "extern \"C\" \n",
    "__global__ void fractal(double* c, int* fractal, int height, int width, int maxiterations) {\n",
    "    const int x = threadIdx.x + blockIdx.x*blockDim.x;\n",
    "    const int y = threadIdx.y + blockIdx.y*blockDim.y;\n",
    "    \n",
    "    // Manual check for out-of-bounds (since blocks may be partial)\n",
    "    if (x >= height || y >= width)\n",
    "        return;\n",
    "    \n",
    "    // Access c\n",
    "    double creal = c[2 * (x + height*y)];\n",
    "    double cimag = c[2 * (x + height*y) + 1];\n",
    "    \n",
    "    // z = c\n",
    "    double zreal = creal;\n",
    "    double zimag = cimag;\n",
    "    \n",
    "    fractal[x + height*y] = 0;\n",
    "    for (int i = 0;  i < maxiterations;  i++) {\n",
    "        // z = z*z + c\n",
    "        double zreal_new = zreal*zreal - zimag*zimag + creal;\n",
    "        double zimag_new = 2*zreal*zimag + cimag;\n",
    "        zreal = zreal_new;\n",
    "        zimag = zimag_new;\n",
    "        \n",
    "        if (zreal*zreal + zimag*zimag > 4) {\n",
    "            break;\n",
    "        }\n",
    "        fractal[x + height*y] = i;\n",
    "    }\n",
    "}\n",
    "\"\"\", \"fractal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pycuda(c, fractal, maxiterations):\n",
    "    threadsperblock = (32, 32)\n",
    "    blockspergrid = (\n",
    "        math.ceil(c.shape[0] / threadsperblock[0]),\n",
    "        math.ceil(c.shape[1] / threadsperblock[1]),\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        blockspergrid,\n",
    "        threadsperblock,\n",
    "        [\n",
    "            c.view(cp.double),\n",
    "            fractal,\n",
    "            cp.int32(height),\n",
    "            cp.int32(width),\n",
    "            cp.int32(maxiterations)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, fractal = prepare(height, width, cp)\n",
    "args = prepare_pycuda(c, fractal, maxiterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "cupy_kernel(*args)\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fractal.get());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra features\n",
    "\n",
    "I've skipped a key example not included above: reduction kernels. These let you perform an element-wise calculation as well as a binary reduction (like a sum).\n",
    "\n",
    "You can also use generic (template in C++) types \"T\", and you can use \"raw\" generics, which are arrays that do not participate in the element-wise portion of the kernel (that is, they do not broadcast in Numpy terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New version\n",
    "\n",
    "CuPy 7.0 will bring a host of new features, including:\n",
    "\n",
    "* Remove Python 2 support\n",
    "* RawModule, for building larger projects\n",
    "* NVCC support (instead of just NVRTC)\n",
    "* TensorCore support\n",
    "* High speed CUB routines, like sum and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
