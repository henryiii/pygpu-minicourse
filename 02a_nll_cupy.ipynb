{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting: Computing an NLL\n",
    "\n",
    "We will be using  CuPy to compute a negative log likelihood, for an unbinned fit (not performed). Like before, let's set up the data and then try a solution with Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "dist = np.hstack([\n",
    "    np.random.normal(loc=1, scale=2., size=500_000),\n",
    "    np.random.normal(loc=1, scale=.5, size=500_000)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist, bins='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1/np.sqrt(2*np.pi*σ**2) * np.exp(-(x-μ)**2/(2*σ**2))\n",
    "\n",
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)\n",
    "\n",
    "def nll(dist, f_0, mean, sigma, sigma2):\n",
    "    return -np.sum(np.log(add(dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(dist, *np.random.rand(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may get a divide by 0 error, since we are randomly setting parameters. That's okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy: simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dist = cp.asarray(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(d_dist, *cp.random.rand(4))\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because CuPy supports the Numpy 1.13 ufunc dispatch, we didn't even need to replace the `np.*` in the lines above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy: Fuse\n",
    "\n",
    "We can get even a *little* better by using fuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cp.fuse()\n",
    "def gaussian(x, μ, σ):\n",
    "    return 1/cp.sqrt(2*cp.pi*σ**2) * cp.exp(-(x-μ)**2/(2*σ**2))\n",
    "\n",
    "@cp.fuse()\n",
    "def add(x, f_0, mean, sigma, sigma2):\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)\n",
    "\n",
    "#@cp.fuse() # Actually slower; it seems to reorder the sum into a linear reduction\n",
    "def nll(dist, f_0, mean, sigma, sigma2):\n",
    "    return -cp.sum(cp.log(add(dist, f_0, mean, sigma, sigma2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(d_dist, *cp.random.rand(4))\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy: Custom kernels\n",
    "\n",
    "Let's try a custom reduction kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_fns = '''\n",
    "#define POW2(x) ((x)*(x))\n",
    "__device__\n",
    "double gaussian(double x, double mu, double sigma) {\n",
    "    return rsqrt(2*M_PI*POW2(sigma)) * exp(-POW2(x-mu)/(2*POW2(sigma)));\n",
    "}\n",
    "\n",
    "__device__ double add(double x, double f_0, double mean, double sigma, double sigma2) {\n",
    "    return f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_kernel = cp.ReductionKernel(\n",
    "    in_params = 'T dist, T f_0, T mean, T sigma, T sigma2',\n",
    "    out_params = 'T y',\n",
    "    map_expr = f\"log(add(dist, f_0, mean, sigma, sigma2))\",\n",
    "    reduce_expr = 'a + b',\n",
    "    post_map_expr = 'y = -a',\n",
    "    identity = '0',\n",
    "    name = 'nll_kernel',\n",
    "    preamble = device_fns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, when we run, we get a nice speedup combined with the large linear reduction slowdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll_kernel(d_dist, *cp.random.rand(4))\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CuPy Elementwise + sum algorithm\n",
    "\n",
    "This is the best we can do (without implementing a RawKernel with a smart reduction, anyway):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_nll = cp.ElementwiseKernel(\n",
    "    in_params = 'T dist, T f_0, T mean, T sigma, T sigma2',\n",
    "    out_params = 'T y',\n",
    "    operation = 'y = log(add(dist, f_0, mean, sigma, sigma2))',\n",
    "    name = 'inside_nll',\n",
    "    preamble = device_fns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "-cp.sum(inside_nll(d_dist, *cp.random.rand(4)))\n",
    "cp.cuda.get_current_stream().synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Take one or more of the above examples, and convert them to 32 bit floats. How does the performance compare? (Pay attention to the GPU you get when running the example).\n",
    "\n",
    "Be careful when you do so not to let 64 bits sneak in. Check the output and/or in-between steps regularly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyGPU Course 2019/12 [course/pygpu/default]",
   "language": "python",
   "name": "sys_pygpu201912"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
