{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4575a55-e1b2-4ee8-9cba-257212934011",
   "metadata": {},
   "source": [
    "# Intro: CuPy and Numba on the GPU\n",
    "\n",
    "10-20-2021\n",
    "\n",
    "\n",
    "Useful links:\n",
    "* [High Performance Python: CPUs](https://github.com/henryiii/python-performance-minicourse)\n",
    "* [iscinumpy.gitlab.io](https://iscinumpy.gitlab.io)\n",
    "* [CompClass](https://github.com/henryiii/compclass)\n",
    "\n",
    "Note that we are using CPython 3.9. 3.10 is out, but is not quite ready for conda yet. And even when it is, Numba is slow to update due to heavy usage of bytecode, which is not (supposed to be) stable between releases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66b640-8e48-451c-9f6c-f3f8db03c7e9",
   "metadata": {},
   "source": [
    "## Problem 1: Negative Log Likelihood\n",
    "\n",
    "Let's start with a NLL calculation. If you are doing an unbinned likelihood fit, this is main computation loop that drives that sort of fit. It's also _mostly_ embarrassingly parallel, except for a final reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1482b-5a33-4614-bd01-36f14fe54bb3",
   "metadata": {},
   "source": [
    "### NumPy (normal CPU solution)\n",
    "\n",
    "Let's try with numpy so you can see the three lines of actual code involved. First our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18534ad-b843-4bd4-bfa8-becf5b350488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d015e9b-2eba-4b17-8dab-9acfc49e4bd3",
   "metadata": {},
   "source": [
    "Now we make some artificial data to run on (this is what we'd fit if we added the fitter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4285ea09-0b30-48f9-b2f8-71467dcb2509",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "dist = np.hstack(\n",
    "    [\n",
    "        rng.normal(loc=1, scale=2.0, size=500_000),\n",
    "        rng.normal(loc=1, scale=0.5, size=500_000),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d24f2-0c57-49d3-80fc-aa329b7c2c8f",
   "metadata": {},
   "source": [
    "Now we define a gaussian, product of two gaussians, and an nll function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60acd4c-132b-4d03-a94a-618d96e38ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, μ, σ):\n",
    "    return 1 / math.sqrt(2 * np.pi * σ**2) * np.exp(-((x - μ) ** 2) / (2 * σ**2))\n",
    "\n",
    "\n",
    "def add(x, f_0, μ, σ_1, σ_2):\n",
    "    return f_0 * gaussian(x, μ, σ_1) + (1 - f_0) * gaussian(x, μ, σ_2)\n",
    "\n",
    "\n",
    "def nll(x, f_0, μ, σ_1, σ_2):\n",
    "    return -np.sum(np.log(add(x, f_0, μ, σ_1, σ_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf36950-1995-43c8-9145-5164cad744bf",
   "metadata": {},
   "source": [
    "Let's just show the actual value at the minimum for comparison later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea84184-840a-4a34-ac83-6026a3570427",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll(dist, 0.5, 1.0, 2.0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b748987-94c7-4ffc-a729-f4673229cdf5",
   "metadata": {},
   "source": [
    "Let's see how much time this takes to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548b64c-792d-4abe-a0cd-b49f04c4c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(\n",
    "    dist,\n",
    "    rng.random(),\n",
    "    rng.normal(loc=1, scale=0.3),\n",
    "    rng.normal(loc=2, scale=0.5),\n",
    "    rng.normal(loc=0.5, scale=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b0fc0-5630-41ec-a838-79d4c7f7c572",
   "metadata": {},
   "source": [
    "FYI, this is _very_ good. NumPy is probably using multiple threads for parts of this computation, and fusing simple expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12bc9a3-7b68-4114-9548-3ffa314a0317",
   "metadata": {},
   "source": [
    "### CuPy\n",
    "\n",
    "#### CuPy drop-in\n",
    "\n",
    "We are going to import cupy. `import cupy as cp` is very common, due to similarly with `np` (and you will sometimes see `import cupy as np`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ed27e-6ba1-4546-8a87-1173811d4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e3eaf-8a39-4e79-b22a-9a224b61f5d0",
   "metadata": {},
   "source": [
    "The first thing we need to do is move the NumPy array over to the GPU. We do that with `cupy.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e373fb-11c0-40e9-bae0-992155b121dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpdist = cupy.array(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cb1f6-908a-4ca9-88f9-762f52a6e8ce",
   "metadata": {},
   "source": [
    "Actually, that's the last thing we need to do, as long as you have NumPy 1.18 or better. Everything works now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a63f1-ad8b-48ad-8fbf-7305245c9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(\n",
    "    cpdist,\n",
    "    rng.random(),\n",
    "    rng.normal(loc=1, scale=0.3),\n",
    "    rng.normal(loc=2, scale=0.5),\n",
    "    rng.normal(loc=0.5, scale=0.1),\n",
    ").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d25568-f723-4399-9ce9-9f25064de5a4",
   "metadata": {},
   "source": [
    "NumPy 1.13 added the ability to override UFuncts, and 1.18 added the ability to override general functions, and CuPy uses this; you don't need to replace `np` with `cupy` unless you are making arrays (`array`, `asarray`, `empty`, `zeros`, etc.). If you do need to make an array, you can use `xp = cupy.get_array_module(existing_array)`, then `xp` will be either `numpy` or `cupy`, depending on the input array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6fca6-946f-4d27-b027-50b0d1f3b2d4",
   "metadata": {},
   "source": [
    "We can try to do better, though - cupy is making temporaries, which are costly. Since we are doing a reduction, let's write a reduction kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069bac6-5248-4bbc-8276-b32ce78fa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rku = cupy.ReductionKernel(\n",
    "    \"float64 x, float64 f_0, float64 mean, float64 sigma, float64 sigma2\",\n",
    "    \"float64 r\",\n",
    "    \"\"\"\n",
    "    log(     f_0  * rsqrt(2*M_PI*sigma*sigma)   * exp(-(x-mean)*(x-mean)/(2*sigma*sigma)) +\n",
    "        (1 - f_0) * rsqrt(2*M_PI*sigma2*sigma2) * exp(-(x-mean)*(x-mean)/(2*sigma2*sigma2)))\n",
    "    \"\"\",\n",
    "    \"a + b\",\n",
    "    \"r = -a\",\n",
    "    \"0\",\n",
    "    \"redu_kernel\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcedfd1-7cfa-459e-86e4-8b4d459ead37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(dist, f_0, mean, sigma, sigma2):\n",
    "    return rku(dist, f_0, mean, sigma, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9199f7-119f-47f8-95c3-641f8ef18975",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll(cpdist, 0.5, 1.0, 2.0, 0.5).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42482bb-a4f7-4541-aa17-446fadd56acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(\n",
    "    cpdist,\n",
    "    rng.random(),\n",
    "    rng.normal(loc=1, scale=0.3),\n",
    "    rng.normal(loc=2, scale=0.5),\n",
    "    rng.normal(loc=0.5, scale=0.1),\n",
    ").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9452b7f-a5b3-4901-975d-f6e46a8372b4",
   "metadata": {},
   "source": [
    "This is actually a bit worse. We did much better in the middle, not needing as many temporaries, but did much worse in the reduction, as this is not as optimized as `cp.sum`. Let's try a hybrid solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570ec62-2465-499f-a624-bc66a18b05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mykernel = cupy.ElementwiseKernel(\n",
    "    \"float64 x, float64 f_0, float64 mean, float64 sigma, float64 sigma2\",\n",
    "    \"float64 z\",\n",
    "    \"\"\"\n",
    "    \n",
    "    double s12 = 2*sigma*sigma;\n",
    "    double s22 = 2*sigma2*sigma2;\n",
    "    \n",
    "    double p = -(x-mean)*(x-mean);\n",
    "    double g = rsqrt(M_PI*s12) * exp(p/s12);\n",
    "    double g2 = rsqrt(M_PI*s22) * exp(p/s22);\n",
    "    \n",
    "    z = log(f_0 * g + (1 - f_0) * g2);\n",
    "        \n",
    "    \"\"\",\n",
    "    \"mykernel\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3cd7f-9ef9-4085-a885-35740239991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(dist, f_0, mean, sigma, sigma2):\n",
    "    return -cupy.sum(mykernel(dist, f_0, mean, sigma, sigma2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19233ac-e605-4760-bdea-7694a2235758",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll(cpdist, 0.5, 1.0, 2.0, 0.5).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1c290-1dbc-4ad4-9b98-2ebe74a8e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(\n",
    "    cpdist,\n",
    "    rng.random(),\n",
    "    rng.normal(loc=1, scale=0.3),\n",
    "    rng.normal(loc=2, scale=0.5),\n",
    "    rng.normal(loc=0.5, scale=0.1),\n",
    ").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab90bd6-77d8-4ba8-80f8-3949937e3b38",
   "metadata": {},
   "source": [
    "This is optimal - we are using the CUB sum as well as avoiding temporaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24461dd2-e663-4caa-ad1a-b469f9cf099a",
   "metadata": {},
   "source": [
    "## Numba GPU\n",
    "\n",
    "Another solution is Numba's JIT compiler, which supports CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df237f3-8cd1-434f-9e11-026c9914eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.cuda\n",
    "import math\n",
    "\n",
    "\n",
    "@numba.cuda.jit(\"float64(float64,float64,float64)\", device=True, inline=True)\n",
    "def gaussian(x, μ, σ):\n",
    "    return 1 / math.sqrt(2 * np.pi * σ**2) * math.exp(-((x - μ) ** 2) / (2 * σ**2))\n",
    "\n",
    "\n",
    "@numba.vectorize([\"float64(float64,float64,float64,float64,float64)\"], target=\"cuda\")\n",
    "def log_add(x, f_0, mean, sigma, sigma2):\n",
    "    return -math.log(\n",
    "        f_0 * gaussian(x, mean, sigma) + (1 - f_0) * gaussian(x, mean, sigma2)\n",
    "    )\n",
    "\n",
    "\n",
    "@numba.cuda.reduce\n",
    "def sum_reduce(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def nll(dist, f_0, mean, sigma, sigma2):\n",
    "    return sum_reduce(log_add(dist, f_0, mean, sigma, sigma2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25072a53-73a9-4bf8-abdd-823a7f5b5ad7",
   "metadata": {},
   "source": [
    "Numba and CuPy support 0-cost transfer between libraries, so you can select the tool that's best for you! We'll make a Numba device vector from our CuPy one. `cupy.asarray(nbdist)` would convert back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80879e-88e3-4873-9ced-ee9dffb3b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbdist = numba.cuda.to_device(cpdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb11cd4-422e-4660-9528-48c980e371d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll(nbdist, 0.5, 1.0, 2.0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942114a0-0f7b-41a2-a1fb-315317508ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nll(\n",
    "    nbdist,\n",
    "    rng.random(),\n",
    "    rng.normal(loc=1, scale=0.3),\n",
    "    rng.normal(loc=2, scale=0.5),\n",
    "    rng.normal(loc=0.5, scale=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659e0f9-7156-43ca-bd54-4b8a21a4ebf7",
   "metadata": {},
   "source": [
    "This is basically on par with the ReductionKernel, as expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyGPU Course 2019/12 [course/pygpu/default]",
   "language": "python",
   "name": "sys_pygpu201912"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
